{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "This notebook checks if the available general tutorials run without errors.  \n",
    "\n",
    "This particulary tests the installed python packages and their interoperability for standard features and examples. Running these checks can take **a lot of time** and there for will not finish in the max. cpu-time we provide for a process on a login node. Hence the jupyter kernel for this notebook will eventually be killed by the system. These Sanity Checks are primarily usefull for system administrators.  \n",
    "\n",
    "If you want to run them anyway - ensure your Jupyter is running as a **batch job** with far more compute time available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Tutorials from Git-Repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "#repo = Repo.clone_from(\"https://gitlab.version.fz-juelich.de/jupyter4jsc/j4j_notebooks.git\", './j4j_notebooks')\n",
    "#repo.git.checkout('integration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Funktions for later Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Tuple, Dict, Mapping\n",
    "from collections import defaultdict\n",
    "from nbformat import NotebookNode\n",
    "\n",
    "def count_source(source: str) -> Tuple[int, int, int]:\n",
    "    \"\"\"Count number of non-blank lines, words, and non-whitespace characters.\n",
    "\n",
    "    :param source: string to count\n",
    "    :return: number of non-blank lines, words, and non-whitespace characters\n",
    "    \"\"\"\n",
    "    lines = [line for line in source.split('\\n') if line and not line.isspace()]\n",
    "    words = source.split()\n",
    "    chars = ''.join(words)\n",
    "\n",
    "    return len(lines), len(words), len(chars)\n",
    "\n",
    "REQUIRED_NB_FIELDS = {\"metadata\", \"nbformat_minor\", \"nbformat\", \"cells\"}\n",
    "REQUIRED_NB_METADATA_FIELDS = {\"kernelspec\", \"language_info\"}\n",
    "CELL_TYPES = ('markdown', 'code', 'raw', )\n",
    "REQUIRED_CELL_FIELDS = {\n",
    "    'markdown': {\"cell_type\", \"metadata\", \"source\"},\n",
    "    'code': {\"cell_type\", \"metadata\", \"source\", \"execution_count\", \"outputs\"},\n",
    "    'raw': {\"cell_type\", \"metadata\", \"source\"}\n",
    "}\n",
    "OPTIONAL_CELL_FIELDS = {\n",
    "    'markdown': {\"attachments\"},\n",
    "    'code': set(),\n",
    "    'raw': {\"attachments\"}\n",
    "}\n",
    "OPTIONAL_OUTPUT_TYPES = {\n",
    "    'execute_result': {'data', 'metadata' ,'execution_count'},\n",
    "    'stream': {'name', 'text'},\n",
    "    'display_data': {'data', 'metadata', },\n",
    "    'error': {'ename', 'evalue', 'traceback'},\n",
    "}\n",
    "\n",
    "CELL_STATISTICS = (\n",
    "    'cell_types',  #: cell type counts\n",
    "    'sources', #: cell sources counts\n",
    "    'cell_metadata',  #: cell metadata counts, including separate ``tags``\n",
    "    'cell_attachments',  #: cell attachment MIME type counts, and total\n",
    "    'code_execution',  #: code cell execution count statistics\n",
    "    'code_outputs',  #: code cell counts per output_type, subcounts per ``stream`` and ``error``, and total\n",
    "    'cell_extra',  #: counts for extra (unknown) fields in cells\n",
    ")\n",
    "\n",
    "# dictionary keys for source statistics\n",
    "EMPTY_SOURCES = 'total empty sources'\n",
    "SOURCE_LINES = 'total source lines'\n",
    "SOURCE_WORDS = 'total source words'\n",
    "SOURCE_CHARS = 'total source chars'\n",
    "EMPTY_SOURCES_MD = 'markdown empty sources'\n",
    "SOURCE_LINES_MD = 'markdown source lines'\n",
    "SOURCE_WORDS_MD = 'markdown source words'\n",
    "SOURCE_CHARS_MD = 'markdown source chars'\n",
    "EMPTY_SOURCES_CODE = 'code empty sources'\n",
    "SOURCE_LINES_CODE = 'code source lines'\n",
    "SOURCE_WORDS_CODE = 'code source words'\n",
    "SOURCE_CHARS_CODE = 'code source chars'\n",
    "EMPTY_SOURCES_RAW = 'raw empty sources'\n",
    "SOURCE_LINES_RAW = 'raw source lines'\n",
    "SOURCE_WORDS_RAW = 'raw source words'\n",
    "SOURCE_CHARS_RAW = 'raw source chars'\n",
    "\n",
    "def nb_cell_stats(nb: NotebookNode) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"Count occurrences of various elements in notebook cells.\n",
    "\n",
    "    :param nb: notebook to inspect\n",
    "    :return: dictionary of dictionaries with counts per section;\n",
    "        each section has its own key; see CELL_STATISTICS\n",
    "    \"\"\"\n",
    "    # process the notebook cells\n",
    "    result = {key: defaultdict(int) for key in CELL_STATISTICS}\n",
    "\n",
    "    # traverse all cells and gather statistics\n",
    "    for index, cell in enumerate(nb.cells):  # index can be used for debug output\n",
    "        result['cell_types']['total cell count'] += 1  # count all cells\n",
    "        ct = cell.cell_type\n",
    "        result['cell_types'][ct] += 1  # count each cell type\n",
    "\n",
    "        # compute source statistics\n",
    "        lines, words, chars = count_source(cell.source)  # cell.source should always be present\n",
    "        empty_cell = chars == 0\n",
    "        if empty_cell:\n",
    "            result['sources'][EMPTY_SOURCES] += 1\n",
    "            if ct == 'markdown':\n",
    "                result['sources'][EMPTY_SOURCES_MD] += 1\n",
    "            elif ct == 'code':\n",
    "                result['sources'][EMPTY_SOURCES_CODE] += 1\n",
    "            elif ct == 'raw':\n",
    "                result['sources'][EMPTY_SOURCES_RAW] += 1\n",
    "        if chars:\n",
    "            result['sources'][SOURCE_LINES] += lines\n",
    "            result['sources'][SOURCE_WORDS] += words\n",
    "            result['sources'][SOURCE_CHARS] += chars\n",
    "            if ct == 'markdown':\n",
    "                result['sources'][SOURCE_LINES_MD] += lines\n",
    "                result['sources'][SOURCE_WORDS_MD] += words\n",
    "                result['sources'][SOURCE_CHARS_MD] += chars\n",
    "            elif ct == 'code':\n",
    "                result['sources'][SOURCE_LINES_CODE] += lines\n",
    "                result['sources'][SOURCE_WORDS_CODE] += words\n",
    "                result['sources'][SOURCE_CHARS_CODE] += chars\n",
    "            elif ct == 'raw':\n",
    "                result['sources'][SOURCE_LINES_RAW] += lines\n",
    "                result['sources'][SOURCE_WORDS_RAW] += words\n",
    "                result['sources'][SOURCE_CHARS_RAW] += chars\n",
    "\n",
    "        # count each metadata key\n",
    "        for attr in cell.metadata:  # cell.metadata should always be present\n",
    "                result['cell_metadata'][attr] += 1\n",
    "\n",
    "        # count each tag in tags metadata\n",
    "        if 'tags' in cell.metadata:\n",
    "            for tag in cell.metadata.tags:\n",
    "                result['cell_metadata']['tag ' + tag] += 1\n",
    "\n",
    "        # count each attachment mime type\n",
    "        if 'attachments' in cell:\n",
    "            result['cell_attachments']['total count of cells with attachments'] += 1\n",
    "            for attachment in cell.attachments.values():\n",
    "                for key in attachment:\n",
    "                    result['cell_attachments']['total attachments count'] += 1\n",
    "                    result['cell_attachments'][key] += 1\n",
    "\n",
    "        # count non-standard fields in cells\n",
    "        for field in cell:\n",
    "            if field not in REQUIRED_CELL_FIELDS[ct].union(OPTIONAL_CELL_FIELDS[ct]):\n",
    "                result['cell_extra'][field] += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "DEFAULT_WIDTH = 10\n",
    "def print_dict(d: Dict[str, Any], header: str=None, width: int=DEFAULT_WIDTH) -> None:\n",
    "    \"\"\"Print dictionary d with section header.\n",
    "\n",
    "    :param d: dictionary to print\n",
    "    :param header: header of the table\n",
    "    :param width: width of the left column\n",
    "    \"\"\"\n",
    "    if d:\n",
    "        if header:\n",
    "            print('{}:'.format(header))\n",
    "        for key in sorted(d):\n",
    "            if key == 'raw':\n",
    "                style = Fore.RED\n",
    "            else:\n",
    "                style = ''\n",
    "            left = str(d[key])\n",
    "            print(style + '  {:>{}} {}'.format(left, width, key) + Style.RESET_ALL)\n",
    "            \n",
    "from pathlib import Path\n",
    "from nbformat import NotebookNode\n",
    "from typing import List, Union\n",
    "import nbformat\n",
    "import sys\n",
    "\n",
    "def read_nb(nb_path: Path) -> Union[None, NotebookNode]:\n",
    "    \"\"\"Read notebook from given path, and return it.\n",
    "    Uses ``args.debug``: in debug mode, a read error results in an exception, else it returns ``None``.\n",
    "\n",
    "    :param nb_path: path to read from\n",
    "    :param args: to check debug mode\n",
    "    :return: notebook read from ``nb_path`` or None if reading failed``\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nb = nbformat.read(nb_path.open(encoding='utf-8'), as_version=4)\n",
    "    except Exception as e:\n",
    "        ename = type(e).__name__\n",
    "        print('Reading of \"{}\" failed ({}):\\n  {}'.format(nb_path.name, ename, e), file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import papermill as pm\n",
    "from papermill.exceptions import PapermillExecutionError\n",
    "\n",
    "failed_notebooks = list()\n",
    "dirbase=\"/p/project/cjsc/goebbert1/j4j_notebooks/001-Jupyter/001-Tutorials/\"\n",
    "for dirpath, dirs, files in os.walk(dirbase):\n",
    "    dirs.sort()\n",
    "    if os.path.basename(dirpath).startswith('.'):\n",
    "        continue\n",
    "    for filename in sorted(files):\n",
    "        if filename.endswith('.ipynb') and not filename.startswith('papermill_'):\n",
    "            print(os.path.join(dirpath,filename))\n",
    "            if filename == \"SanityCheck-Tutorials.ipynb\":\n",
    "                continue\n",
    "            try:\n",
    "                os.chdir(dirpath)\n",
    "                nb_path = os.path.join(dirpath, filename)\n",
    "                \n",
    "                # get notebook statistics\n",
    "                nb = read_nb(Path(nb_path))\n",
    "                cell_stats = nb_cell_stats(nb)\n",
    "                print_dict(cell_stats['cell_types'], \"Cell types\")\n",
    "                #print_dict(cell_stats['sources'], \"Cell sources\")\n",
    "                #print_dict(cell_stats['cell_metadata'], \"Cell metadata fields\")\n",
    "                #print_dict(cell_stats['cell_attachments'], \"Cell attachments\")             \n",
    "                \n",
    "                # execute notebook\n",
    "                try:\n",
    "                    nb = pm.execute_notebook(\n",
    "                        nb_path,\n",
    "                        os.path.join(dirpath, 'papermill_' + filename),\n",
    "                        #kernel_name=\"Python3\"\n",
    "                    )\n",
    "                except:\n",
    "                    print(\"FAILED !!!!\")\n",
    "                \n",
    "                os.chdir(dirbase)\n",
    "            except PapermillExecutionError as e:\n",
    "                failed_notebooks.append([os.path.join(dirpath, filename), e.evalue])\n",
    "                print(e.evalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import papermill as pm\n",
    "from papermill.exceptions import PapermillExecutionError\n",
    "\n",
    "failed_notebooks = list()\n",
    "dirbase=\"/p/project/cjsc/goebbert1/j4j_notebooks/001-Jupyter/001-Tutorials/\"\n",
    "for dirpath, dirs, files in os.walk(dirbase):\n",
    "    if os.path.basename(dirpath).startswith('.'):\n",
    "        continue\n",
    "    for filename in files:\n",
    "        if filename.endswith('.ipynb') and filename.startswith('papermill_'):\n",
    "            nb_path = os.path.join(dirpath,filename)\n",
    "            print(nb_path)\n",
    "            os.remove(nb_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
