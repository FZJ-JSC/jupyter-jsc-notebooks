{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "# Interactive monitoring of a parallel MPI simulation with the IPython Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from ipyparallel import Client, error\n",
    "\n",
    "cluster = Client(profile=\"mpi\")\n",
    "view = cluster[:]\n",
    "view.block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cluster.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "Now, we load the MPI libraries into the engine namespaces, and do a simple printing of their MPI rank information to verify that all nodes are operational and they match our cluster's real capacity.  \n",
    "\n",
    "Here, we are making use of IPython's special `%%px` cell magic, which marks the entire cell for parallel execution.  This means that the code below will not run in this notebook's kernel, but instead will be sent to *all* engines for execution there.  In this way, IPython makes it very natural to control your entire cluster from within the notebook environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# MPI initialization, library imports and sanity checks on all engines\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mpi = MPI.COMM_WORLD\n",
    "bcast = mpi.bcast\n",
    "barrier = mpi.barrier\n",
    "rank = mpi.rank\n",
    "print(\"MPI rank: %i/%i\" % (mpi.rank,mpi.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "We write a utility that reorders a list according to the mpi ranks of the engines, since all gather operations will return data in engine id order, not in MPI rank order.  We'll need this later on when we want to reassemble in IPython data structures coming from all the engines: IPython will collect the data ordered by engine ID, but our code creates data structures based on MPI rank, so we need to map from one indexing scheme to the other.  This simple function does the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "ranks = view['rank']\n",
    "rank_indices = np.argsort(ranks)\n",
    "\n",
    "def mpi_order(seq):\n",
    "    \"\"\"Return elements of a sequence ordered by MPI rank.\n",
    "\n",
    "    The input sequence is assumed to be ordered by engine ID.\"\"\"\n",
    "    return [seq[x] for x in rank_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "## MPI simulation example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "This is our 'simulation', a toy example that computes $\\sin(f(x^2+y^2))$ for a slowly increasing frequency $f$ over a gradually refined mesh.  In a real-world example, there typically is a 'simulate' method that, afer setting up initial parameters, runs the entire computation.  But having this simple example will be sufficient to see something that changes visually as the computation evolves and that is quick enough for us to test.\n",
    "\n",
    "And while simple, this example has a realistic decomposition of the spatial domain in one array per MPI node that requires care in reordering the data for visualization, as would be needed in a real-world application (unless your code accumulates data in the rank 0 node that you can grab directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "stop = False\n",
    "nsteps = 100\n",
    "delay = 0.1\n",
    "\n",
    "xmin, xmax = 0, np.pi\n",
    "ymin, ymax = 0, 2*np.pi\n",
    "dy = (ymax-ymin)/mpi.size\n",
    "\n",
    "def simulation():\n",
    "    \"\"\"Toy simulation code, computes sin(f*(x**2+y**2)) for a slowly increasing f\n",
    "    over an increasingly fine mesh.\n",
    "\n",
    "    The purpose of this code is simply to illustrate the basic features of a typical\n",
    "    MPI code: spatial domain decomposition, a solution which is evolving in some \n",
    "    sense, and local per-node computation.  In this case the nodes don't really\n",
    "    communicate at all.\n",
    "    \"\"\"\n",
    "    # By making these few variables global, we allow the IPython client to access them\n",
    "    # remotely for interactive introspection\n",
    "    global j, Z, nx, nyt\n",
    "    freqs = np.linspace(0.6, 1, nsteps)\n",
    "    for j in range(nsteps):\n",
    "        nx, ny = 2+j/4, 2+j/2/mpi.size\n",
    "        nyt = mpi.size*ny\n",
    "        Xax = np.linspace(xmin, xmax, nx)\n",
    "        Yax = np.linspace(ymin+rank*dy, ymin+(rank+1)*dy, ny, endpoint=rank==mpi.size)\n",
    "        X, Y = np.meshgrid(Xax, Yax)\n",
    "        f = freqs[j]\n",
    "        Z = np.cos(f*(X**2 + Y**2))\n",
    "        # We add a small delay to simulate that a real-world computation\n",
    "        # would take much longer, and we ensure all nodes are synchronized\n",
    "        time.sleep(delay)\n",
    "        # The stop flag can be set remotely via IPython, allowing the simulation to be\n",
    "        # cleanly stopped from the outside\n",
    "        if stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "## IPython tools to interactively monitor and plot the MPI results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "We now define a local (to this notebook) plotting function that fetches data from the engines' global namespace.  Once it has retrieved the current state of the relevant variables, it produces and returns a figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_current_results(in_place=True):\n",
    "    \"\"\"Makes a blocking call to retrieve remote data and displays the solution mesh\n",
    "    as a contour plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_place : bool\n",
    "        By default it calls clear_output so that new plots replace old ones.  Set\n",
    "        to False to allow keeping of all previous outputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We make a blocking call to load the remote data from the simulation into simple named \n",
    "    # variables we can read from the engine namespaces\n",
    "    #view.apply_sync(load_simulation_globals)\n",
    "    # And now we can use the view to read these variables from all the engines.  Then we\n",
    "    # concatenate all of them into single arrays for local plotting\n",
    "    try:\n",
    "        Z = np.concatenate(mpi_order(view['Z']))\n",
    "    except ValueError:\n",
    "        print(\"dimension mismatch in Z, not plotting\")\n",
    "        ax = plt.gca()\n",
    "        return ax.figure\n",
    "        \n",
    "    nx, nyt, j, nsteps = view.pull(['nx', 'nyt', 'j', 'nsteps'], targets=0)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contourf(Z)\n",
    "    ax.set_title('Mesh: %i x %i, step %i/%i' % (nx, nyt, j+1, nsteps))\n",
    "    plt.axis('off')\n",
    "    # We clear the notebook output before plotting this if in-place plot updating is requested\n",
    "    if in_place:\n",
    "        clear_output(wait=True)\n",
    "    display(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "It will also be useful to be able to check whether the simulation is still alive or not.  Below we will wrap the main simulation function into a thread to allow IPython to pull data from the engines, and we will call this object `simulation_thread`.  So to check whether the code is still running, all we have to do is call the `is_alive` method on all of our engines and see whether any of them returns True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "def simulation_alive():\n",
    "    \"\"\"Return True if the simulation thread is still running on any engine.\n",
    "    \"\"\"\n",
    "    return any(view.apply_sync(lambda : simulation_thread.is_alive()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "Finally, this is a convenience wrapper around the plotting code so that we can interrupt monitoring at any point, and that will provide basic timing information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "def monitor_simulation(refresh=5.0, plots_in_place=True):\n",
    "    \"\"\"Monitor the simulation progress and call plotting routine.\n",
    "\n",
    "    Supress KeyboardInterrupt exception if interrupted, ensure that the last \n",
    "    figure is always displayed and provide basic timing and simulation status.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    refresh : float\n",
    "      Refresh interval between calls to retrieve and plot data.  The default\n",
    "      is 5s, adjust depending on the desired refresh rate, but be aware that \n",
    "      very short intervals will start having a significant impact.\n",
    "\n",
    "    plots_in_place : bool\n",
    "       If true, every new figure replaces the last one, producing a (slow)\n",
    "       animation effect in the notebook.  If false, all frames are plotted\n",
    "       in sequence and appended in the output area.\n",
    "    \"\"\"\n",
    "    import datetime as dt, time\n",
    "    \n",
    "    if not simulation_alive():\n",
    "        plot_current_results(in_place=plots_in_place)\n",
    "        plt.close('all')\n",
    "        print('Simulation has already finished, no monitoring to do.')\n",
    "        return\n",
    "    \n",
    "    t0 = dt.datetime.now()\n",
    "    fig = None\n",
    "    try:\n",
    "        while simulation_alive():\n",
    "            fig = plot_current_results(in_place=plots_in_place)\n",
    "            plt.close('all') # prevent re-plot of old figures\n",
    "            time.sleep(refresh) # so we don't hammer the server too fast\n",
    "    except (KeyboardInterrupt, error.TimeoutError):\n",
    "        msg = 'Monitoring interrupted, simulation is ongoing!'\n",
    "    else:\n",
    "        msg = 'Simulation completed!'\n",
    "    tmon = dt.datetime.now() - t0\n",
    "    if plots_in_place and fig is not None:\n",
    "        clear_output(wait=True)\n",
    "        plt.close('all')\n",
    "        display(fig)\n",
    "    print(msg)\n",
    "    print('Monitored for: %s.' % tmon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "## Making a simulation object that can be monitored interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "from threading import Thread\n",
    "stop = False\n",
    "nsteps = 100\n",
    "delay=0.5\n",
    "# Create a thread wrapper for the simulation. The target must be an argument-less\n",
    "# function so we wrap the call to 'simulation' in a simple lambda:\n",
    "simulation_thread = Thread(target = lambda : simulation())\n",
    "# Now we actually start the simulation\n",
    "simulation_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "monitor_simulation(refresh=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_start": false
    }
   },
   "source": [
    "If you execute the following cell before the MPI code is finished running, it will stop the simulation at that point, which you can verify by calling the monitoring again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_start": false
    }
   },
   "outputs": [],
   "source": [
    "view['stop'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "from IPython.parallel import bind_kernel; bind_kernel()\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "%qtconsole"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
